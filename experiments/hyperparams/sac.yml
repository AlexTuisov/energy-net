
# ==== Custom Envs ===
energy_net-v0:
  env_wrapper:
    - gymnasium.wrappers.time_limit.TimeLimit:
        max_episode_steps: 480
    - rl_zoo3.wrappers.HistoryWrapper:
        horizon: 48
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  learning_rate: 0.0017
  buffer_size: 100000
  batch_size: 64
  ent_coef: 'auto'
  gamma: 0.99
  tau: 0.01
  normalize: true
  # train_freq: 64
  train_freq: 128
  # gradient_steps: -1
  gradient_steps: 64
  learning_starts: 1000
  use_sde_at_warmup: True
  use_sde: True
  sde_sample_freq: 64
  policy_kwargs: "dict(log_std_init=-2, net_arch=[64, 64])"

