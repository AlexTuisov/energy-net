
# ==== Custom Envs ===
energy_net-v0:
  env_wrapper:
    - gymnasium.wrappers.time_limit.TimeLimit:
        max_episode_steps: 480
    - rl_zoo3.wrappers.HistoryWrapper:
        horizon: 48
  normalize: true
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  ent_coef: 9.6e-5
  max_grad_norm: 0.5
  n_steps: 8
  gae_lambda: 0.9
  vf_coef: 0.4
  gamma: 0.95
  use_rms_prop: True
  normalize_advantage: False
  # Both works
  learning_rate: !!float 3.2e-5
  # learning_rate: !!float 3e-4
  use_sde: True
  policy_kwargs: "dict(log_std_init=-2, ortho_init=False)"

